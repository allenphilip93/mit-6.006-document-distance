{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# docdist1 - initial version of document distance\n",
    "# docdist2 - changed concatenate to extend in get_words_from_line_list\n",
    "# docdist3 - improved dot product to exploit sorted order and achieve\n",
    "#               linear instead of quadratic time\n",
    "# docdist4 - changed count_frequency to use dictionaries instead of lists\n",
    "# docdist5 - change get_words_from_string to use string translate and split\n",
    "# docdist6 - changed sorting from insertion sort to merge sort\n",
    "# docdist7 - remove sorting altogether via more hashing\n",
    "# docdist8 - treat whole file as a single \"line\"\n",
    "# \n",
    "#\n",
    "# Original version by Ronald L. Rivest on February 14, 2007\n",
    "# Revision by Erik D. Demaine on September 12, 2011\n",
    "#\n",
    "# Usage:\n",
    "#    filename.py filename1 filename2\n",
    "#     \n",
    "# This program computes the \"distance\" between two text files\n",
    "# as the angle between their word frequency vectors (in radians).\n",
    "#\n",
    "# For each input file, a word-frequency vector is computed as follows:\n",
    "#    (1) the specified file is read in\n",
    "#    (2) it is converted into a list of alphanumeric \"words\"\n",
    "#        Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "#        characters.  Non-alphanumeric characters are treated as blanks.\n",
    "#        Case is not significant.\n",
    "#    (3) for each word, its frequency of occurrence is determined\n",
    "#    (4) the word/frequency lists are sorted into order alphabetically\n",
    "#\n",
    "# The \"distance\" between two vectors is the angle between them.\n",
    "# If x = (x1, x2, ..., xn) is the first vector (xi = freq of word i)\n",
    "# and y = (y1, y2, ..., yn) is the second vector,\n",
    "# then the angle between them is defined as:\n",
    "#    d(x,y) = arccos(inner_product(x,y) / (norm(x)*norm(y)))\n",
    "# where:\n",
    "#    inner_product(x,y) = x1*y1 + x2*y2 + ... xn*yn\n",
    "#    norm(x) = sqrt(inner_product(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File pg-grimm.txt : 9569 lines, 105324 words, 5172 distinct words\n",
      "File pg-huckleberry_finn.txt : 12361 lines, 120896 words, 6519 distinct words\n",
      "The distance between the documents is: 0.460007 (radians)\n",
      "         635390 function calls (612012 primitive calls) in 1.422 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.000    0.000 :0(_getdefaultlocale)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "       40    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "   131832    0.094    0.000    0.094    0.000 :0(append)\n",
      "      145    0.031    0.000    0.031    0.000 :0(charmap_decode)\n",
      "        1    0.000    0.000    1.422    1.422 :0(exec)\n",
      "    33619    0.031    0.000    0.031    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "        2    0.000    0.000    0.000    0.000 :0(items)\n",
      "   368280    0.328    0.000    0.328    0.000 :0(len)\n",
      "        2    0.000    0.000    0.000    0.000 :0(open)\n",
      "        9    0.000    0.000    0.016    0.002 :0(print)\n",
      "        2    0.000    0.000    0.031    0.016 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "    21930    0.047    0.000    0.047    0.000 :0(split)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "    21930    0.078    0.000    0.078    0.000 :0(translate)\n",
      "        2    0.000    0.000    0.031    0.016 <ipython-input-168-bd4f635b6556>:1(read_file)\n",
      "        3    0.031    0.010    0.078    0.026 <ipython-input-182-32bcbf5db45c>:1(inner_product_ver3)\n",
      "        1    0.000    0.000    0.078    0.078 <ipython-input-183-de378fe69ed6>:1(vector_angle_ver3)\n",
      "        2    0.031    0.016    0.031    0.016 <ipython-input-186-af3548656aa2>:1(count_frequency_ver4)\n",
      "    21930    0.109    0.000    0.234    0.000 <ipython-input-190-665a20327a5a>:6(get_words_from_string_ver5)\n",
      "        2    0.062    0.031    0.297    0.148 <ipython-input-191-4891eb0c5166>:1(get_words_from_line_list_ver5)\n",
      "  23380/2    0.109    0.000    0.969    0.484 <ipython-input-195-7474511251a3>:1(merge_sort)\n",
      "    11689    0.453    0.000    0.828    0.000 <ipython-input-195-7474511251a3>:13(merge)\n",
      "        1    0.000    0.000    1.422    1.422 <ipython-input-197-ee9f6fd79e85>:1(ver6)\n",
      "        2    0.000    0.000    1.344    0.672 <ipython-input-206-e8dc9dfae686>:1(word_frequencies_for_file_ver6)\n",
      "        1    0.000    0.000    1.422    1.422 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 _bootlocale.py:11(getpreferredencoding)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
      "      145    0.000    0.000    0.031    0.000 cp1252.py:22(decode)\n",
      "       40    0.000    0.000    0.016    0.000 iostream.py:195(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:313(_schedule_flush)\n",
      "       38    0.000    0.000    0.016    0.000 iostream.py:366(write)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        1    0.000    0.000    1.422    1.422 profile:0(ver6())\n",
      "       40    0.016    0.000    0.016    0.000 socket.py:333(send)\n",
      "       40    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       40    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "       40    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import profile\n",
    "    profile.run(\"ver6()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \",filename)\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    word_list = []          # accumulates words in line\n",
    "    character_list = []     # accumulates characters in word\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list)>0:\n",
    "            word = \"\".join(character_list)\n",
    "            word = word.lower()\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = \"\".join(character_list)\n",
    "        word = word.lower()\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, in place.\n",
    "\n",
    "    From Cormen/Leiserson/Rivest/Stein,\n",
    "    Introduction to Algorithms (second edition), page 17,\n",
    "    modified to adjust for fact that Python arrays use \n",
    "    0-indexing.\n",
    "    \"\"\"\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j-1\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(L1,L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as lists of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    for word1, count1 in L1:\n",
    "        for word2, count2 in L2:\n",
    "            if word1 == word2:\n",
    "                sum += count1 * count2\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle(L1,L2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return math.acos(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver1():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist2 - changed concatenate to extend in get_words_from_line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list_ver2(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        # Using \"extend\" is much more efficient than concatenation here:\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file_ver2(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list_ver2(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver2():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver2(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver2(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist3 - improved dot product to exploit sorted order and achieve\n",
    "#            linear instead of quadratic time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_ver3(L1,L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                        3   [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle_ver3(L1,L2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product_ver3(L1,L2)\n",
    "    denominator = math.sqrt(inner_product_ver3(L1,L1)*inner_product_ver3(L2,L2))\n",
    "    return math.acos(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver3():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver2(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver2(filename_2)\n",
    "    distance = vector_angle_ver3(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist4 - changed count_frequency to use dictionaries instead of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency_ver4(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    D = {}\n",
    "    for new_word in word_list:\n",
    "        if new_word in D:\n",
    "            D[new_word] = D[new_word]+1\n",
    "        else:\n",
    "            D[new_word] = 1\n",
    "    return list(D.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file_ver4(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list_ver2(line_list)\n",
    "    freq_mapping = count_frequency_ver4(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver4():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver4(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver4(filename_2)\n",
    "    distance = vector_angle_ver3(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist5 - change get_words_from_string to use string translate and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables needed for fast parsing\n",
    "# translation table maps upper case to lower case and punctuation to spaces\n",
    "translation_table = str.maketrans(string.punctuation+string.ascii_uppercase,\n",
    "                                     \" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "\n",
    "def get_words_from_string_ver5(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list_ver5(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string_ver5(line)\n",
    "        # Using \"extend\" is much more efficient than concatenation here:\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file_ver5(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list_ver5(line_list)\n",
    "    freq_mapping = count_frequency_ver4(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver5():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver5(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver5(filename_2)\n",
    "    distance = vector_angle_ver3(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist6 - changed sorting from insertion sort to merge sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, and return result.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    if n==1: \n",
    "        return A\n",
    "    mid = n//2     # floor division\n",
    "    L = merge_sort(A[:mid])\n",
    "    R = merge_sort(A[mid:])\n",
    "    return merge(L,R)\n",
    "\n",
    "def merge(L,R):\n",
    "    \"\"\"\n",
    "    Given two sorted sequences L and R, return their merge.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    j = 0\n",
    "    answer = []\n",
    "    while i<len(L) and j<len(R):\n",
    "        if L[i]<R[j]:\n",
    "            answer.append(L[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            answer.append(R[j])\n",
    "            j += 1\n",
    "    if i<len(L):\n",
    "        answer.extend(L[i:])\n",
    "    if j<len(R):\n",
    "        answer.extend(R[j:])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file_ver6(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list_ver5(line_list)\n",
    "    freq_mapping = count_frequency_ver4(word_list)\n",
    "    freq_mapping = merge_sort(freq_mapping)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver6():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver6(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver6(filename_2)\n",
    "    distance = vector_angle_ver3(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist7 - remove sorting altogether via more hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency_ver7(word_list):\n",
    "    \"\"\"\n",
    "    Return a dictionary mapping words to frequency.\n",
    "    \"\"\"\n",
    "    D = {}\n",
    "    for new_word in word_list:\n",
    "        if new_word in D:\n",
    "            D[new_word] = D[new_word]+1\n",
    "        else:\n",
    "            D[new_word] = 1\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_ver7(D1,D2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as dictionaries of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product({\"and\":3,\"of\":2,\"the\":5},\n",
    "                           {\"and\":4,\"in\":1,\"of\":1,\"this\":2}) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    for key in D1:\n",
    "        if key in D2:\n",
    "            sum += D1[key] * D2[key]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle_ver7(D1,D2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product_ver7(D1,D2)\n",
    "    denominator = math.sqrt(inner_product_ver7(D1,D1)*inner_product_ver7(D2,D2))\n",
    "    return math.acos(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file_ver7(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list_ver5(line_list)\n",
    "    freq_mapping = count_frequency_ver7(word_list)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver7():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver7(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver7(filename_2)\n",
    "    distance = vector_angle_ver7(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist8 - treat whole file as a single \"line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_ver8(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "        return f.read()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \",filename)\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list_ver8(text):\n",
    "    \"\"\"\n",
    "    Parse the given text into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    text = text.translate(translation_table)\n",
    "    word_list = text.split()\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file_ver8(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file_ver8(filename)\n",
    "    word_list = get_words_from_line_list_ver8(line_list)\n",
    "    freq_mapping = count_frequency_ver7(word_list)\n",
    "\n",
    "    print(\"File\",filename,\":\", end=' ')\n",
    "    print(len(line_list),\"lines,\", end=' ')\n",
    "    print(len(word_list),\"words,\", end=' ')\n",
    "    print(len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver8():\n",
    "    filename_1 = \"pg-grimm.txt\"\n",
    "    filename_2 = \"pg-huckleberry_finn.txt\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file_ver8(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file_ver8(filename_2)\n",
    "    distance = vector_angle_ver7(sorted_word_list_1,sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
